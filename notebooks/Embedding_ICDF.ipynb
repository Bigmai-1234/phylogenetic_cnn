{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data & Feature Selection & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load_raw_data\n",
    "DISEASE_NAME = 'HS_iCDf'\n",
    "DATASET_FOLDER = os.path.join('..', 'datasets/ibd_dataset', DISEASE_NAME)\n",
    "training_file = os.path.join(DATASET_FOLDER, 'Sokol_16S_taxa_HS_iCDf_commsamp_training.txt')\n",
    "training_labs = os.path.join(DATASET_FOLDER, 'Sokol_16S_taxa_HS_iCDf_commsamp_training_lab.txt')\n",
    "test_file = os.path.join(DATASET_FOLDER, 'Sokol_16S_taxa_HS_iCDf_commsamp_test.txt')\n",
    "test_labs = os.path.join(DATASET_FOLDER, 'Sokol_16S_taxa_HS_iCDf_commsamp_test_lab.txt')\n",
    "df_train = pd.read_csv(training_file,  sep='\\t', index_col=0, header=0)\n",
    "df_test = pd.read_csv(test_file,  sep='\\t', index_col=0, header=0)\n",
    "y_train, y_test = np.loadtxt(training_labs, dtype=np.int), np.loadtxt(test_labs, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [  6  47  65  76 112 187 235] are constant.\n",
      "  UserWarning)\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "kbest = SelectKBest(k=62)\n",
    "kbest = kbest.fit(df_train, y_train)\n",
    "index_ranked = kbest.get_support(True)\n",
    "cols = list()\n",
    "for i in index_ranked:\n",
    "    cols.append(df_train.columns.values[i])\n",
    "df_train_fs = df_train[cols]\n",
    "df_test_fs = df_test[cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_fs.astype(dtype=np.float32)\n",
    "X_test = df_test_fs.astype(dtype=np.float32)\n",
    "X = np.vstack((X_train, X_test))\n",
    "y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 62), (24, 62), (82, 62), (82,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Coordinates\n",
    "COORD_FILEPATH = os.path.join('..', 'datasets/coordinates/', 'coordinates_icdf.txt')\n",
    "coords = pd.read_csv(COORD_FILEPATH, sep='\\t', \n",
    "                     header=0, index_col=0)\n",
    "coords = coords.astype(dtype=np.float32)\n",
    "nb_coordinates = coords.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Embeddings of Data (ICDF)\n",
    "\n",
    "Color Code: \n",
    "\n",
    "* <span style=\"color: green;\"> Healty Subjects</span>\n",
    "* <span style=\"color: red;\"> ICDf Subjects</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {1: 'green', 0: 'red'}\n",
    "colors = [colormap[v] for v in y]\n",
    "from sklearn.manifold._t_sne import TSNE\n",
    "tsne = TSNE(n_components=2, n_iter=5000, perplexity=5)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "X.shape, X_tsne.shape\n",
    "p = figure(title = \"iCDf Data\", plot_width=400, plot_height=400)\n",
    "p.xaxis.axis_label = 'First Component'\n",
    "p.yaxis.axis_label = 'Second Component'\n",
    "\n",
    "p.circle(X_tsne[:, 0], X_tsne[:,1],\n",
    "         color=colors, fill_alpha=0.2, size=10)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract PhyloConv Layer Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.backend import floatx\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import (Lambda, MaxPooling1D, Flatten,\n",
    "                          Dropout, Dense, BatchNormalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "D:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Change PYTHONPATH to allow for relative import\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from phcnn.layers import PhyloConv1D, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_coordinates = np.empty((X.shape[0],) + coords.shape, dtype=np.float64)\n",
    "for i in range(X.shape[0]):\n",
    "    all_coordinates[i] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 62), (306, 247), (82, 306, 247))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,coords.shape,all_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_coordinates = all_coordinates[..., np.newaxis]\n",
    "X = X[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 306, 247, 1), (82, 62, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coordinates.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_features = 62  # current nb of features in the feature step!\n",
    "# Paramenters for phylo_conv layers\n",
    "list_filters = [16, 16]\n",
    "list_neighbours = [4, 4]\n",
    "# Parameter for output layer\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WEIGHT_FILE = os.path.join(os.path.abspath(os.path.curdir), 'icdf_phcnn_model_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PhCNN Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "data = Input(shape=(nb_features, 1), name=\"data\", dtype=floatx())\n",
    "coordinates = Input(shape=(nb_coordinates, nb_features, 1),\n",
    "                    name=\"coordinates\", dtype=floatx())\n",
    "\n",
    "\n",
    "conv_layer = data\n",
    "# We remove the padding that we added to work around keras limitations\n",
    "conv_crd = Lambda(lambda c: c[0], output_shape=lambda s: (s[1:]))(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "coordinates (InputLayer)        (None, 306, 62, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data (InputLayer)               (None, 62, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (306, 62, 1)         0           coordinates[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "phylo_conv1d_1 (PhyloConv1D)    [(None, 62, 16), (30 80          data[0][0]                       \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "phylo_conv1d_2 (PhyloConv1D)    [(None, 62, 16), (30 1040        phylo_conv1d_1[0][0]             \n",
      "                                                                 phylo_conv1d_1[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 31, 16)       0           phylo_conv1d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 496)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 128)          63616       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_l (Dropout)             (None, 128)          0           fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "new_output (Dense)              (None, 2)            258         dropout_l[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,994\n",
      "Trainable params: 63,874\n",
      "Non-trainable params: 1,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for nb_filters, nb_neighbors in zip(list_filters, list_neighbours):\n",
    "\n",
    "    if nb_neighbors > nb_features:\n",
    "        raise Exception(\"More neighbors than features, \"\n",
    "                        \"please use less neighbors or use more features\")\n",
    "\n",
    "    distances = euclidean_distances(conv_crd)\n",
    "    conv_layer, conv_crd = PhyloConv1D(distances,  \n",
    "                                       nb_neighbors, \n",
    "                                       nb_filters,activation='selu', trainable=False)([conv_layer, conv_crd])\n",
    "    \n",
    "# import pdb;pdb.set_trace()\n",
    "maxp = MaxPooling1D(pool_size=2, padding=\"valid\")(conv_layer)\n",
    "flatt = Flatten()(maxp)\n",
    "fc_1 = Dense(units= 128, name='fc_1', activation='sigmoid')(flatt)\n",
    "dropout = Dropout(0.25, name=\"dropout_l\")(fc_1)\n",
    "output = Dense(units=nb_classes, kernel_initializer=\"he_normal\",\n",
    "               activation=\"softmax\", name='new_output')(dropout)\n",
    "\n",
    "model = Model(inputs=[data, coordinates], outputs=output)\n",
    "\n",
    "#model.load_weights(WEIGHT_FILE, by_name=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_conv_activations(model, layer, Coords, X_batch):\n",
    "    \"\"\"Tensorflow function to extract activations from target layer tensor(s).\n",
    "    This function is supposed to be applied to a Convolutional Layer, so the\n",
    "    outputs of the function will be the list of all tensors (i.e. cnn filters.)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: keras.models.Model\n",
    "        Instance of the target model (i.e. PhCNN network)\n",
    "    layer: keras.layers.convolutional._Conv\n",
    "        Instance of the target Convolutional Layer from which \n",
    "        extract output tensors\n",
    "    Coords:  array-like, shape: (batch_size, nb_coords, nb_features, 1)\n",
    "        Tensor of Coordinates\n",
    "    X_batch: array-like, shape: (batch_size, nb_features, 1)\n",
    "        Tensor of batch data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        List of tensor objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    activations_f = K.function(inputs=[model.layers[0].input, \n",
    "                                       model.layers[1].input,\n",
    "                                       K.learning_phase()], \n",
    "                               outputs=[t for t in layer.output])\n",
    "    \n",
    "    activations = activations_f((Coords, X_batch, False))\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Target Network Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phyloconv_layer_1 = model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phylo_conv1d_1'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phyloconv_layer_1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'coordinates:0' shape=(?, 306, 62, 1) dtype=float32>,\n",
       " <tf.Tensor 'data:0' shape=(?, 62, 1) dtype=float32>,\n",
       " <tf.Tensor 'keras_learning_phase:0' shape=() dtype=bool>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input, model.layers[1].input,K.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'phylo_conv1d_1/mul_1:0' shape=(?, 62, 16) dtype=float32>,\n",
       " <tf.Tensor 'phylo_conv1d_1/mul_3:0' shape=(306, 62, 16) dtype=float32>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phyloconv_layer_1.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get PhyloConv Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "transpose expects a vector of size 7. But input(1) is a vector of size 3\n\t [[{{node phylo_conv1d_1/transpose_2}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_data_0_1, phylo_conv1d_1/transpose_2/perm)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-97a9d51a8955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_acts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_conv_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphyloconv_layer_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_coordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-163-50730fa8381e>\u001b[0m in \u001b[0;36mget_conv_activations\u001b[1;34m(model, layer, Coords, X_batch)\u001b[0m\n\u001b[0;32m     26\u001b[0m                                outputs=[t for t in layer.output])\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\devtools\\anaconda\\envs\\xbiome\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: transpose expects a vector of size 7. But input(1) is a vector of size 3\n\t [[{{node phylo_conv1d_1/transpose_2}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_data_0_1, phylo_conv1d_1/transpose_2/perm)]]"
     ]
    }
   ],
   "source": [
    "conv_acts = get_conv_activations(model, phyloconv_layer_1, all_coordinates, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_acts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-3f1933cffc35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_acts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_acts' is not defined"
     ]
    }
   ],
   "source": [
    "conv_acts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_acts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-7c762fb8c66d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_acts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_acts' is not defined"
     ]
    }
   ],
   "source": [
    "X_cnn = conv_acts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Embeddings of PhCnn Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f8a98ecc24c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# nb filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mX_cnn_tsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cnn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         p = figure(title = \"PhyloConv filter {}\".format(i+1), \n\u001b[0;32m      6\u001b[0m                    plot_width=400, plot_height=400)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, n_iter=5000, perplexity=5)\n",
    "for i in range(16):  # nb filters\n",
    "    try:\n",
    "        X_cnn_tsne = tsne.fit_transform(X_cnn[:, :, i])\n",
    "        p = figure(title = \"PhyloConv filter {}\".format(i+1), \n",
    "                   plot_width=400, plot_height=400)\n",
    "        p.xaxis.axis_label = 'First Component'\n",
    "        p.yaxis.axis_label = 'Second Component'\n",
    "\n",
    "        p.circle(X_cnn_tsne[:, 0], X_cnn_tsne[:,1],\n",
    "                 color=colors, fill_alpha=0.2, size=10)\n",
    "        show(p)\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xbiome",
   "language": "python",
   "name": "xbiome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
